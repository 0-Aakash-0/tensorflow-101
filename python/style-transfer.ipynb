{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IS96273\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg19\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image_path = \"C:/Users/IS96273/Desktop/content.jpeg\"\n",
    "style_image_path = \"C:/Users/IS96273/Desktop/style.jpg\"\n",
    "\n",
    "height = 224; weight = 224 #original size of vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(height, weight))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0) #layer block1_conv1: expected ndim=4, found ndim=3\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = preprocess_image(content_image_path)\n",
    "style_image = preprocess_image(style_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pixels = np.random.randint(256, size=(height, weight, 3))\n",
    "generated_image = preprocess_input(np.expand_dims(random_pixels, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(content_image.shape)\n",
    "print(style_image.shape)\n",
    "print(generated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_model = vgg19.VGG19(input_tensor=K.variable(content_image), weights='imagenet')\n",
    "style_model = vgg19.VGG19(input_tensor=K.variable(content_image), weights='imagenet')\n",
    "generated_model = vgg19.VGG19(input_tensor=K.variable(generated_image), weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_outputs = dict([(layer.name, layer.output) for layer in content_model.layers])\n",
    "style_outputs = dict([(layer.name, layer.output) for layer in style_model.layers])\n",
    "generated_outputs = dict([(layer.name, layer.output) for layer in generated_model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(content, generated):\n",
    "    return K.sum(K.square(content - generated))\n",
    "\n",
    "content_features = content_outputs['block5_conv2']\n",
    "generated_features = generated_outputs['block5_conv2']\n",
    "\n",
    "contentloss = content_loss(content_features, generated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, generated):\n",
    "    style_gram = gram_matrix(style)\n",
    "    content_gram = gram_matrix(generated)\n",
    "    channels = 3\n",
    "    size = height * weight\n",
    "    return K.sum(K.square(style_gram - content_gram)) / (4. * (pow(channels,2)) * (pow(size,2)))\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "\n",
    "styleloss = K.variable(0)\n",
    "for layer_name in feature_layers:\n",
    "    style_features = style_outputs[layer_name]\n",
    "    generated_features = generated_outputs[layer_name]\n",
    "    styleloss = styleloss + style_loss(style_features[0], generated_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.025; beta = 0.2\n",
    "total_loss = alpha * contentloss + beta * styleloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients/block1_conv1_2/convolution_grad/Conv2DBackpropInput:0\", shape=(1, 224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#gradients = K.gradients(loss, generated_model.trainable_weights)\n",
    "gradients = K.gradients(total_loss, generated_model.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients/block1_conv1_2/convolution_grad/Conv2DBackpropInput:0\", shape=(1, 224, 224, 3), dtype=float32)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(gradients[0])\n",
    "print(generated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = np.array([0.1])\n",
    "#generated_image = generated_image - learning_rate * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
